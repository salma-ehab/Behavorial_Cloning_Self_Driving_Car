{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6b5c0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-27T16:44:22.634643Z",
     "iopub.status.busy": "2022-05-27T16:44:22.634089Z",
     "iopub.status.idle": "2022-05-27T16:44:22.874677Z",
     "shell.execute_reply": "2022-05-27T16:44:22.873761Z"
    },
    "papermill": {
     "duration": 0.249518,
     "end_time": "2022-05-27T16:44:22.877256",
     "exception": false,
     "start_time": "2022-05-27T16:44:22.627738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#Remove parts of the image (the hood of the car and the part that's past the horizon) as these parts are useless\n",
    "def removeImagePart(image, top, bottom):\n",
    "  return image[top:bottom, :]\n",
    "\n",
    "#Resize the image and reduce the time needed for training\n",
    "def resizeImage(image, dimension):\n",
    "  return cv2.resize(image, dimension, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#Preprocessing the image by removing the unnecessary parts and resizing it to be 64 by 64\n",
    "def preprocessImage(image, top=60, bottom=140, dimension=(64, 64)):\n",
    "  return resizeImage(removeImagePart(image, top, bottom), dimension)\n",
    "\n",
    "#Get certain view of the image with its angle randomly\n",
    "def getImageAngle(row,randomCamera, angle=0.23):\n",
    "\n",
    "    #Get left view. Thus, the angle is added\n",
    "    if randomCamera == 0:\n",
    "        image_path = row.left.split('\\\\')[-1]\n",
    "        angle = row.angle + angle\n",
    "\n",
    "    #Get center view. Thus, the angle is the same   \n",
    "    elif randomCamera == 1:\n",
    "        image_path = row.center.split('\\\\')[-1]\n",
    "        angle = row.angle\n",
    "\n",
    "    #Get right view. Thus, the angle is subtracted      \n",
    "    else:\n",
    "        image_path = row.right.split('\\\\')[-1]\n",
    "        angle = row.angle - angle\n",
    "\n",
    "    #Retieve the image\n",
    "    image = mpimg.imread('../input/drivingcarimg/IMG/' + image_path)\n",
    "\n",
    "    return image, angle\n",
    "\n",
    "#Get a certain view of the image along with its angle\n",
    "def randomCamera(row):\n",
    "  randomCamera= np.random.randint(0, 3)\n",
    "  image, angle = getImageAngle(row, randomCamera)\n",
    "  return image, angle\n",
    "\n",
    "#Flip the image half the time and change the angle accordingly\n",
    "def flipImage(image, angle):\n",
    "  if np.random.binomial(1, 0.5):\n",
    "    return cv2.flip(image, 1), -angle\n",
    "  else:\n",
    "    return image, angle\n",
    "\n",
    "#Change the brightness of the image\n",
    "def adjustBrightness(image):\n",
    "  #0.4(duller) and 1.5(brighter)\n",
    "  gamma = np.random.uniform(0.4, 1.5)\n",
    "  inverseGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** inverseGamma) * 255\n",
    "                    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  return cv2.LUT(image, table)\n",
    "\n",
    "#Shear the image horizontally to simulate a bending road by letting the pixels at the bottom of the image remain fixed \n",
    "#while the pixels at the top row are moved randomly to the left or right.\n",
    "def shearImage(image, angle, shear_range=200):\n",
    "  rows, cols, _ = image.shape\n",
    "  dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "  randomPoint = [cols / 2 + dx, rows / 2]\n",
    "  points1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "  points2 = np.float32([[0, rows], [cols, rows], randomPoint])\n",
    "  dangle = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "  M = cv2.getAffineTransform(points1, points2)\n",
    "  image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)  \n",
    "  return image, angle + dangle\n",
    "\n",
    "#Shift the image vertically randomly to simulate the road in the second track.\n",
    "def randomBumps(image, y_range=20):\n",
    "  rows, cols, _ = image.shape\n",
    "  dy = (y_range * np.random.uniform()) - (y_range / 2)\n",
    "  M = np.float32([[1, 0, 0], [0, 1, dy]])\n",
    "  return cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "#Augment the images\n",
    "def augmentData(image, angle):\n",
    "  #90% of the images are sheared\n",
    "  if np.random.binomial(1, 0.9):\n",
    "    image, angle = shearImage(image, angle)\n",
    "  image, angle = flipImage(image, angle)\n",
    "  image = adjustBrightness(image)\n",
    "  image = preprocessImage(image)\n",
    "  image = randomBumps(image)\n",
    "  return image, angle\n",
    "\n",
    "#Give headers to the driving-log file and read it\n",
    "def read_csv(path):\n",
    "  headers = ['center', 'left', 'right', 'angle', 'throttle', 'brake', 'speed']\n",
    "  return pd.read_csv(path, names=headers, skiprows=1)\n",
    "\n",
    "#Get data needed for training(all the data obtained fom the driving-log file) and validation (all data with non-zero angles\n",
    "#and only a 0.1 fraction of data with zero angles)\n",
    "def getData():\n",
    "    trainingData = read_csv('../input/drivingcar/driving_log.csv')   \n",
    "    nonZeroTrainingData = trainingData[trainingData.angle != 0]\n",
    "    zeroTrainingData = trainingData[trainingData.angle == 0]\n",
    "    validationData = pd.concat([nonZeroTrainingData, zeroTrainingData.sample(frac=0.1)], ignore_index=True)\n",
    "    return trainingData, validationData\n",
    "\n",
    "#Get training batch\n",
    "def trainingBatch(trainData, batchSize):\n",
    "  total = len(trainData)\n",
    "  while True:\n",
    "    images = []\n",
    "    angles = []\n",
    "    #Get random batches\n",
    "    randoms= np.random.randint(0, total, batchSize)\n",
    "    for index in randoms:\n",
    "      row = trainData.iloc[index]\n",
    "      #Retieve the image along with its angle\n",
    "      image, angle = randomCamera(row)\n",
    "      ##Retieve the augmented image and its angle\n",
    "      image, angle = augmentData(image, angle)\n",
    "      images.append(image)\n",
    "      angles.append(angle)\n",
    "\n",
    "    yield np.array(images), np.array(angles)\n",
    "\n",
    "#Get validation batch\n",
    "def validationBatch(validationData, batchSize):\n",
    "  total = len(validationData)\n",
    "  current = 0\n",
    "  while True:\n",
    "    images = []\n",
    "    angles = []\n",
    "    for index in range(batchSize):\n",
    "      row = validationData.iloc[current]\n",
    "      #Retieve the center view of the image along with its angle\n",
    "      image, angle = getImageAngle(row, 1)\n",
    "      images.append(preprocessImage(image))\n",
    "      angles.append(angle)\n",
    "      current = (current + 1) % total\n",
    "\n",
    "    yield np.array(images), np.array(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6efe5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-27T16:44:22.885938Z",
     "iopub.status.busy": "2022-05-27T16:44:22.885659Z",
     "iopub.status.idle": "2022-05-28T02:40:27.727247Z",
     "shell.execute_reply": "2022-05-28T02:40:27.726277Z"
    },
    "papermill": {
     "duration": 35767.21131,
     "end_time": "2022-05-28T02:40:30.092356",
     "exception": false,
     "start_time": "2022-05-27T16:44:22.881046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 16:44:29.526812: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 24)        1824      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 30, 30, 24)        21600     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 24)        14424     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 13, 13, 24)        4056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 24)          14424     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 5, 5, 24)          600       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 5, 24)          96        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 64)          13888     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 5, 5, 64)          1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 4, 4, 64)          1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 10)                10        \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111,879\n",
      "Trainable params: 111,459\n",
      "Non-trainable params: 420\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 16:44:30.710286: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - 1251s 4s/step - loss: 0.4179 - val_loss: 0.4473\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1232s 4s/step - loss: 0.2372 - val_loss: 0.1255\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1188s 4s/step - loss: 0.1674 - val_loss: 0.0864\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1231s 4s/step - loss: 0.1377 - val_loss: 0.0745\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1191s 4s/step - loss: 0.1200 - val_loss: 0.0740\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1269s 4s/step - loss: 0.1068 - val_loss: 0.0675\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1323s 4s/step - loss: 0.0979 - val_loss: 0.0643\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1131s 4s/step - loss: 0.0906 - val_loss: 0.0635\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1142s 4s/step - loss: 0.0853 - val_loss: 0.0602\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1133s 4s/step - loss: 0.0803 - val_loss: 0.0608\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1133s 4s/step - loss: 0.0769 - val_loss: 0.0608\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1144s 4s/step - loss: 0.0740 - val_loss: 0.0625\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1126s 4s/step - loss: 0.0703 - val_loss: 0.0597\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1366s 5s/step - loss: 0.0670 - val_loss: 0.0610\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1446s 5s/step - loss: 0.0646 - val_loss: 0.0618\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1194s 4s/step - loss: 0.0643 - val_loss: 0.0615\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1161s 4s/step - loss: 0.0613 - val_loss: 0.0619\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1180s 4s/step - loss: 0.0583 - val_loss: 0.0617\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1152s 4s/step - loss: 0.0567 - val_loss: 0.0605\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1177s 4s/step - loss: 0.0560 - val_loss: 0.0603\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1185s 4s/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1186s 4s/step - loss: 0.0534 - val_loss: 0.0608\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1155s 4s/step - loss: 0.0531 - val_loss: 0.0599\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1140s 4s/step - loss: 0.0510 - val_loss: 0.0593\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1165s 4s/step - loss: 0.0501 - val_loss: 0.0572\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1161s 4s/step - loss: 0.0495 - val_loss: 0.0603\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1140s 4s/step - loss: 0.0481 - val_loss: 0.0606\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1127s 4s/step - loss: 0.0475 - val_loss: 0.0609\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1183s 4s/step - loss: 0.0465 - val_loss: 0.0584\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1143s 4s/step - loss: 0.0460 - val_loss: 0.0584\n"
     ]
    }
   ],
   "source": [
    "#Imports   \n",
    "from keras.layers import Dense, Flatten, Lambda, PReLU, MaxPooling2D, Dropout\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#Model architecture\n",
    "def get_model():\n",
    "  model = Sequential()\n",
    "  #Normalization\n",
    "  model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(64, 64, 3)))\n",
    "\n",
    "  #Convolutional and maxpooling layers\n",
    "  model.add(Conv2D(filters=24, kernel_size=(5, 5), padding='valid', strides=(2, 2),kernel_regularizer=regularizers.l2(0)))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Conv2D(filters=24, kernel_size=(5, 5), padding='valid', strides=(2, 2),kernel_regularizer=regularizers.l2(0)))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Conv2D(filters=24, kernel_size=(5, 5), padding='valid', strides=(2, 2),kernel_regularizer=regularizers.l2(0)))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Conv2D(filters=64,kernel_size=( 3, 3), padding='same', strides=(1, 1),kernel_regularizer=regularizers.l2(0)))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "  model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1),kernel_regularizer=regularizers.l2(0)))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "\n",
    "  model.add(AveragePooling2D(pool_size=(3, 3), strides=(1, 1)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  # fully connected layer\n",
    "  model.add(Dense(10))\n",
    "  model.add(PReLU())\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1, activation='tanh'))\n",
    "\n",
    "  return model\n",
    "\n",
    "def main():\n",
    "  #Get training and validation data\n",
    "  trainDriving, validDriving = getData()\n",
    "  \n",
    "  #Get model\n",
    "  model = get_model()\n",
    "  #Get the details of the architecture\n",
    "  model.summary()\n",
    "\n",
    "  #Generators for traindrivinging and validation\n",
    "  BATCH = 100\n",
    "  trainDrivingGenerator = trainingBatch(trainDriving, BATCH)\n",
    "  validationDrivingGenerator = validationBatch(validDriving, BATCH)\n",
    "\n",
    "  #Train\n",
    "  EPOCHS = 30\n",
    "  traindrivingS = 300 #22455/(5*3)\n",
    "  VALIDS = 4491\n",
    "  model.compile(optimizer=Adam( 1e-4), loss=\"mse\")\n",
    "  history = model.fit(trainDrivingGenerator,\n",
    "                                steps_per_epoch=traindrivingS,\n",
    "                                epochs=EPOCHS,\n",
    "                                validation_data=validationDrivingGenerator,\n",
    "                                validation_steps=VALIDS,\n",
    "                                verbose=1)\n",
    "\n",
    "\n",
    "  #Save the model\n",
    "  from tensorflow.keras.models import save_model\n",
    "  model.save('/kaggle/working/model2.h5')\n",
    "  #model.save('./model.h5',save_format='h5')\n",
    "\n",
    "  os.chdir(r'/kaggle/working')\n",
    "  from IPython.display import FileLink\n",
    "  FileLink(r'model2.h5')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35781.934456,
   "end_time": "2022-05-28T02:40:35.912652",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-27T16:44:13.978196",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
